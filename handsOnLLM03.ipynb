{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/LeeSeungYun1020/HandsOnLargeLanguageModels/blob/main/handsOnLLM03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnHjyg5YcCIA"
   },
   "source": [
    "# 대규모 언어 모델 개요\n",
    "\n",
    "핸즈온 LLM 3장\n",
    "- 트랜스포머 모델\n",
    "- 트랜스포머 아키텍처의 발전\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Em1PTv-QcITA"
   },
   "source": [
    "# 트랜스포머 모델\n",
    "\n",
    "## 훈련된 트랜스포머 LLM의 입출력\n",
    "- 한 번에 하나의 토큰 생성\n",
    "- 정방향 계산: 프롬프트 -> 모델에 전달 -> 다음 토큰 생성 -> 출력된 토큰을 프롬프트에 추가\n",
    "  - 모든 단계를 순서대로 한 번씩 수행\n",
    "- 자기회귀 모델: 이전 예측 활용하여 다음 예측\n",
    "\n",
    "## 정방향 계산의 구성 요소\n",
    "- 토크나이저, 트랜스포머 블록의 스택, 언어 모델링(LM) 헤드로 구성\n",
    "  - 토크나이저: 토큰의 테이블 어휘사전 포함, 모델은 각 토큰에 해당하는 임베딩(벡터 표현) 가짐\n",
    "    - 텍스트 -> 토큰 -> 토큰 임베딩\n",
    "  - 트랜스포머 블록 스택: 트랜스포머 블록 여러 개 순서대로 통과\n",
    "  - LM 헤드: 다음 토큰 확률로 변환, 다른 헤드를 붙일 수 있음(Ex: 시퀀스 분류 헤드, 토큰 분류 헤드)\n",
    "\n",
    "## 확률 분포에서 하나의 토큰 선택하기\n",
    "- 디코딩 전략: 디코딩 과정에서 얻은 확률 분포에서 토큰 하나를 선택하는 방법, 확률 점수 기반 확률 분포에서 샘플링 수행 아이디어\n",
    "  - 탐욕적 디코딩: 항상 확률이 가장 높은 토큰을 선택\n",
    "  - 무작위성을 가미하거나 2, 3번째 토큰을 선택하는 것이 더 나은 경우도 있음 -> 6장\n",
    "\n",
    "## 병렬 토큰 처리와 문맥 크기\n",
    "- 트랜스포머는 기존 신경망 구조 대비 병렬 처리 향상\n",
    "  - 입력 토큰을 개별 처리 스트림(트랙)으로 보내 처리\n",
    "  - 모델 문맥 크기 = 모델이 다루는 최대 토큰 수 = 스트림 개수\n",
    "\n",
    "## 키와 값을 캐싱하여 생성 속도 향상\n",
    "- 키와 값 캐시: 어텐션 메커니즘에서 이전 스트림 출력을 사용 -> 이전 스트림 결과를 캐싱\n",
    "\n",
    "## 트랜스포머 블록 내부\n",
    "- 피드포워드 신경망: 모델 처리 용량의 대부분 담당\n",
    "  - 정보 저장, 예측 생성, 데이터 보간\n",
    "- 셀프 어텐션: 다른 입력 토큰 위치 정보 통합\n",
    "  - 문맥 통합, 패턴(뉘앙스) 파악\n",
    "  - 이전 토큰이 현재 토큰과 관련도 점수를 매긴 뒤(관련성 점수 계산) 각 토큰에서 얻은 정보를 출력 벡터에 통합(정보 통합)\n",
    "  - 어텐션 헤드: 병렬로 실행되는 어텐션 메커니즘\n",
    "\n",
    "\n",
    "# 트랜스포머 아키텍처의 발전\n",
    "\n",
    "## 효율적인 어텐션\n",
    "- 로컬/희소 어텐션: 주의를 기울일 이전 토큰 문맥 길이 제한\n",
    "- 멀티 쿼리 어텐션: 키와 값 행렬을 모든 헤드에서 공유, 쿼리 행렬만 고유\n",
    "- 그룹 쿼리 어텐션: 키와 값 행렬을 그룹 단위로 공유(품질 향상 위해 메모리 추가 사용), 쿼리 행렬은 고유\n",
    "- 플래시 어텐션: GPU의 SRAM(공유 메모리)과 HBM(고대역폭 메모리) 사이 이동을 최적화하여 계산 속도 향상\n",
    "\n",
    "## 트랜스포머 블록\n",
    "- 선정규화: 어텐션, 피드포워드 과정 이전에 정규화 수행(기존에는 어텐션, 피드포워드 이후에 정규화 수행)\n",
    "- RMS 정규화: 레이어 정규화를 간소화\n",
    "\n",
    "## 위치 임베딩\n",
    "- 모델이 시퀀스 안에서 토큰의 순서를 추적할 수 있는 정보\n",
    "- 로터리 위치 임베딩: 상대적인 토큰 위치 정보를 인코딩\n",
    "  - 훈련 데이터에 여러 문서 포함할 수 있어 대규모 모델 훈련에서 효율성 향상\n",
    "\n",
    "## 실험적 구조와 개선 사항\n",
    "- 컴퓨터 비전, 로봇공학, 시계열 분야에서 트랜스포머 구조 적용 및 연구 중\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aE2RwxUdbptp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "1ca6d6580b624ed1834012769c776d8a",
      "d2df3f67de9b43bb8f302a8b8a120b52",
      "dae48bfabf414230ac8605c213a4cfbf",
      "6bad7a09523c4eaf8465c62b49310364",
      "01fa1926a8a04013ba6c0692f40db22d",
      "09a996b60dfd4902ac6e7568561a0311",
      "2e3067de61af4b78a50b89ceebb4135d",
      "3e7bba5f6c5a4ca9837f8c95015edaa1",
      "81a8ba9620aa41128d791238f43c2691",
      "7596d4cffbb74739a13776cc9d89b842",
      "e0f93f1f746a448da68400c976e2ff4a",
      "fed4773ab85346c5a102548d7bc3549e",
      "588c49e8f99149e5afdb4c102a39ff4c",
      "5a20b2d7d5c14cccb39270a258c65c04",
      "f37b5ba290034add88c36d21c25a2325",
      "c5ae5694baee4841a7d903e9ceaa2941",
      "0c3e3823c41848a6acb1bb076764e601",
      "27c60c714dfe4f7dbbb1f8331efcea9f",
      "cbe8135c09fc4b94a91ad4c21cd27c9a",
      "565ab04e74544b3889e818ffa34d83da",
      "0216c92adc4c456799cb6962ed05e8a9",
      "71161241347b46f8817fa338556fb7e6",
      "1ba8c0e104754fbbb63f3561f973e05e",
      "4d34d5679c8a4928b4d47ae1ba7206f4",
      "cdd7b38bc0bc4ca4a594614b385ecf52",
      "0eddc9154a204b73a9c425c2f5a48045",
      "5a147c8a6b394ea8bd987bc4f68b2642",
      "5afd02c4679844afb8975fdb0a2d8086",
      "b1aab358714844f89b966aac0d71f085",
      "3e7e010c5ab24002ac2e373981d43d33",
      "2edcfc7d3fe346e591180bf93cdcee58",
      "7ca3d88b335544989b61ea4da89f6139",
      "cb256aa80fa043e0a8c41989a4b89f6f",
      "ce4bec245e1a4ae6a2842509144181fa",
      "ed14757df2974bb8a698250d65709b81",
      "dd23958f10e04ec4a326cbf4576df892",
      "a1cc3b5b6e44406990d995d296612a6a",
      "a6fdf6226f3740da8e8c413876eacefe",
      "ce0f82151c4e454da62a126cee7a8049",
      "a9cd654021e5487babfadd16fba7a684",
      "52758fdc274941958f1ceeb5d68e5fe7",
      "90f89cfe73fb4a21ad929fe86546a70f",
      "0172871791a34c57a1f7feea666222c8",
      "466e8532241e4522acc2f6d405be526c",
      "1d2b406ec970412b9b760fe028d3570c",
      "79defe46e68947ee9a5545a26697dfcd",
      "a6f9e02ab7424e05864eb2ce4f472c01",
      "6a67c369bfd14b619e2dd83c203b4f53",
      "5dbf9d3dfea14461bb7a8a661958a89b",
      "df496ecb511a4f0db30145f040ba8699",
      "8e3779d85f68438b8ab67fd552407569",
      "1ac7705e6b1d4c6bbb6eaaef2bc9f6ce",
      "0261eb17e13243afb5281d432b125264",
      "d342d909a6dd4a788867a7ed326c2da4",
      "047843385c974540a3fc037a878797f7"
     ]
    },
    "id": "87ZRQNY-clSR",
    "outputId": "64df755a-5ce0-438d-b535-cb95b1b52360"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca6d6580b624ed1834012769c776d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed4773ab85346c5a102548d7bc3549e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba8c0e104754fbbb63f3561f973e05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4bec245e1a4ae6a2842509144181fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2b406ec970412b9b760fe028d3570c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "3068ebbc97424948bb73f4b52c30c7ec",
      "0a404c70f4494fda8c65a2c288d42226",
      "060de759af8d466eaee10b1e22208dd4",
      "10fabd0be5d64839afab0e6c8d7fd7b1",
      "8093264dadcd427b833a6ae9eb9bc35e",
      "e3bf40ad41594d07a7261c66b126caa1",
      "c7bdf9b92c264231b4944dcc45d063e7",
      "4d65a9c4723f4b289cc821f4fbad53e9",
      "4b3f495c12f84759bf7a9d5250b01ece",
      "267fd01fcf1348e7bb6ac373b84ae61e",
      "7f72d2e4e25b469a84410addebad24b0"
     ]
    },
    "id": "dkRO7JGKdcHT",
    "outputId": "53e857e2-549e-4df2-9e04-78d5ebb1731c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3068ebbc97424948bb73f4b52c30c7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bMYjW4QeHNG",
    "outputId": "6bcce9d3-d501-4a0f-dc33-85eab620bd16"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    return_full_text = False,\n",
    "    max_new_token = 128,\n",
    "    do_sample = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTYXEUqHe4nH",
    "outputId": "d001905d-fa39-46f1-b76c-d9b3ac80056b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write an email apologizing to Yun for the tragic gardening mishap. Explain how it happened.\"\n",
    "output = generator(prompt, do_sample = False, use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BdlCfGQSfP8b",
    "outputId": "15fc9b48-e6a4-4cd8-8536-63dea1823be9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Express your regret and offer to help with the garden repairs.\n",
      "\n",
      "Subject: Sincere Apologies for the Gardening Mishap\n",
      "\n",
      "Dear Yun,\n",
      "\n",
      "I hope this email finds you well. I am writing to express my deepest apologies for the unfortunate incident that occurred in your garden recently. It was truly a tragic mishap, and I am truly sorry for any distress or inconvenience it may have caused you.\n",
      "\n",
      "The incident happened when I was attempting to help you with your gardening project. Unfortunately, due to my lack of experience and knowledge in this area, I unintentionally caused some damage to your plants. I understand that this was not my intention, and I deeply regret the outcome.\n",
      "\n",
      "I realize that my actions have caused you a great deal of frustration and disappointment. Please know that I am truly sorry for any inconvenience this may have caused you. I take full responsibility for my actions and understand that it was my mistake.\n",
      "\n",
      "To make amends, I would like to offer my assistance in repairing the damage done to your garden. I am more than willing to help you with any necessary tasks, such as replanting the damaged\n"
     ]
    }
   ],
   "source": [
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-OGwh0K1fXYU",
    "outputId": "49c95f14-dbf3-4fd3-c3dc-7fbc2003b1e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi3ForCausalLM(\n",
      "  (model): Phi3Model(\n",
      "    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
      "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x Phi3DecoderLayer(\n",
      "        (self_attn): Phi3Attention(\n",
      "          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
      "          (qkv_proj): Linear(in_features=3072, out_features=9216, bias=False)\n",
      "          (rotary_emb): Phi3RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Phi3MLP(\n",
      "          (gate_up_proj): Linear(in_features=3072, out_features=16384, bias=False)\n",
      "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
      "          (activation_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Phi3RMSNorm()\n",
      "        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (post_attention_layernorm): Phi3RMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): Phi3RMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5D58jOSfc2s"
   },
   "outputs": [],
   "source": [
    "prompt = \"The most famous fruit is the\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "input_ids = input_ids.to(\"cuda\")\n",
    "model_output = model.model(input_ids, use_cache=False)\n",
    "lm_head_output = model.lm_head(model_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "y_EIBJi4n_SO",
    "outputId": "8827acbf-0e38-4081-b4c6-458baf6c269d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'apple'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_id = lm_head_output[0,-1].argmax(-1)\n",
    "tokenizer.decode(token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lC2hWzXLoxyZ",
    "outputId": "25c7bf9c-d660-4272-d3b5-847daa7788a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code\n",
      "common\n",
      "example\n",
      "of\n",
      "the\n",
      "apple\n"
     ]
    }
   ],
   "source": [
    "for out in lm_head_output[0]:\n",
    "  print(tokenizer.decode(out.argmax(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0YHbavg1oOOX",
    "outputId": "c0b0c584-e592-44cf-9602-50d0c42582ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 3072])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ApfAUTFPoTvf",
    "outputId": "75b0ab89-582f-4c81-886e-be86d47c205b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 32064])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_head_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Of7RsmIboXEt",
    "outputId": "c997259d-dd42-436d-aa66-7606ee626d71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se\n",
      "oul\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "##\n",
      "#\n",
      "Message\n",
      ":\n",
      "\n",
      "\n",
      "Trans\n",
      "late\n",
      "to\n",
      "English\n",
      ":\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "##\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The capital city of Korea is\"\n",
    "for i in range(1, 20):\n",
    "  input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "  input_ids = input_ids.to(\"cuda\")\n",
    "  model_output = model.model(input_ids, use_cache=False)\n",
    "  lm_head_output = model.lm_head(model_output[0])\n",
    "  token_id = lm_head_output[0,-1].argmax(-1)\n",
    "  print(tokenizer.decode(token_id))\n",
    "  prompt = prompt + tokenizer.decode(token_id)\n",
    "\n",
    "# Seoul은 두 단어로 나누어 토큰화되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUx96V2BscK5"
   },
   "outputs": [],
   "source": [
    "prompt = \"Explain to me about the capital city of Korea.\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUoY6NzNtPsw",
    "outputId": "c0f4840d-446e-4dcb-f043-d8b3da6a7a7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12027,  7420,   304,   592,  1048,   278,  7483,  4272,   310, 19109,\n",
      "         29889,    13,    13,  1068, 13296,   918, 29871, 29896, 29901,  1068,\n",
      "            13,    13,  1576,  7483,  4272,   310, 19109,   338,   922,  5059,\n",
      "         29889,   922,  5059,   338,   278, 10150, 25311,   275,   297,  4275,\n",
      "         19109,   322, 19700,   408,   278,  8604, 29892, 16375, 29892,   322,\n",
      "         17407,  4818,   310,   278,  4234, 29889,   739,   338,  5982,   297,\n",
      "           278,  6641,  5933,   760,   310,   278,  4234, 29892,  2978,   278,\n",
      "          1261,   309,  3673,  1891, 10640,   313, 23560, 29999, 29897,   393,\n",
      "          2903,  1078,   372,   515,  4644, 19109, 29889,    13,    13,  2008,\n",
      "          5059,   338,  2998,   363,   967,  5400,  2071,   952, 29883,  2390,\n",
      "           414, 29892,  1880, 29899, 11345,  1014,  1994, 29892,   322,  1835,\n",
      "          9257, 29892,  3704,   476, 29899,  7323,   322, 22467,  8541,   294,\n",
      "         29889,   450,  4272,   338,   884,  3271,   304,  5112]],\n",
      "       device='cuda:0')\n",
      "tensor([[12027,  7420,   304,   592,  1048,   278,  7483,  4272,   310, 19109,\n",
      "         29889,    13,    13,  1068, 13296,   918, 29871, 29896, 29901,  1068,\n",
      "            13,    13,  1576,  7483,  4272,   310, 19109,   338,   922,  5059,\n",
      "         29889,   922,  5059,   338,   278, 10150, 25311,   275,   297,  4275,\n",
      "         19109,   322, 19700,   408,   278,  8604, 29892, 16375, 29892,   322,\n",
      "         17407,  4818,   310,   278,  4234, 29889,   739,   338,  5982,   297,\n",
      "           278,  6641,  5933,   760,   310,   278,  4234, 29892,  2978,   278,\n",
      "          1261,   309,  3673,  1891, 10640,   313, 23560, 29999, 29897,   393,\n",
      "          2903,  1078,   372,   515,  4644, 19109, 29889,    13,    13,  2008,\n",
      "          5059,   338,  2998,   363,   967,  5400,  2071,   952, 29883,  2390,\n",
      "           414, 29892,  1880, 29899, 11345,  1014,  1994, 29892,   322,  1835,\n",
      "          9257, 29892,  3704,   476, 29899,  7323,   322, 22467,  8541,   294,\n",
      "         29889,   450,  4272,   338,   884,  3271,   304,  5112]],\n",
      "       device='cuda:0')\n",
      "tensor([[12027,  7420,   304,   592,  1048,   278,  7483,  4272,   310, 19109,\n",
      "         29889,    13,    13,  1068, 13296,   918, 29871, 29896, 29901,  1068,\n",
      "            13,    13,  1576,  7483,  4272,   310, 19109,   338,   922,  5059,\n",
      "         29889,   922,  5059,   338,   278, 10150, 25311,   275,   297,  4275,\n",
      "         19109,   322, 19700,   408,   278,  8604, 29892, 16375, 29892,   322,\n",
      "         17407,  4818,   310,   278,  4234, 29889,   739,   338,  5982,   297,\n",
      "           278,  6641,  5933,   760,   310,   278,  4234, 29892,  2978,   278,\n",
      "          1261,   309,  3673,  1891, 10640,   313, 23560, 29999, 29897,   393,\n",
      "          2903,  1078,   372,   515,  4644, 19109, 29889,    13,    13,  2008,\n",
      "          5059,   338,  2998,   363,   967,  5400,  2071,   952, 29883,  2390,\n",
      "           414, 29892,  1880, 29899, 11345,  1014,  1994, 29892,   322,  1835,\n",
      "          9257, 29892,  3704,   476, 29899,  7323,   322, 22467,  8541,   294,\n",
      "         29889,   450,  4272,   338,   884,  3271,   304,  5112]],\n",
      "       device='cuda:0')\n",
      "tensor([[12027,  7420,   304,   592,  1048,   278,  7483,  4272,   310, 19109,\n",
      "         29889,    13,    13,  1068, 13296,   918, 29871, 29896, 29901,  1068,\n",
      "            13,    13,  1576,  7483,  4272,   310, 19109,   338,   922,  5059,\n",
      "         29889,   922,  5059,   338,   278, 10150, 25311,   275,   297,  4275,\n",
      "         19109,   322, 19700,   408,   278,  8604, 29892, 16375, 29892,   322,\n",
      "         17407,  4818,   310,   278,  4234, 29889,   739,   338,  5982,   297,\n",
      "           278,  6641,  5933,   760,   310,   278,  4234, 29892,  2978,   278,\n",
      "          1261,   309,  3673,  1891, 10640,   313, 23560, 29999, 29897,   393,\n",
      "          2903,  1078,   372,   515,  4644, 19109, 29889,    13,    13,  2008,\n",
      "          5059,   338,  2998,   363,   967,  5400,  2071,   952, 29883,  2390,\n",
      "           414, 29892,  1880, 29899, 11345,  1014,  1994, 29892,   322,  1835,\n",
      "          9257, 29892,  3704,   476, 29899,  7323,   322, 22467,  8541,   294,\n",
      "         29889,   450,  4272,   338,   884,  3271,   304,  5112]],\n",
      "       device='cuda:0')\n",
      "tensor([[12027,  7420,   304,   592,  1048,   278,  7483,  4272,   310, 19109,\n",
      "         29889,    13,    13,  1068, 13296,   918, 29871, 29896, 29901,  1068,\n",
      "            13,    13,  1576,  7483,  4272,   310, 19109,   338,   922,  5059,\n",
      "         29889,   922,  5059,   338,   278, 10150, 25311,   275,   297,  4275,\n",
      "         19109,   322, 19700,   408,   278,  8604, 29892, 16375, 29892,   322,\n",
      "         17407,  4818,   310,   278,  4234, 29889,   739,   338,  5982,   297,\n",
      "           278,  6641,  5933,   760,   310,   278,  4234, 29892,  2978,   278,\n",
      "          1261,   309,  3673,  1891, 10640,   313, 23560, 29999, 29897,   393,\n",
      "          2903,  1078,   372,   515,  4644, 19109, 29889,    13,    13,  2008,\n",
      "          5059,   338,  2998,   363,   967,  5400,  2071,   952, 29883,  2390,\n",
      "           414, 29892,  1880, 29899, 11345,  1014,  1994, 29892,   322,  1835,\n",
      "          9257, 29892,  3704,   476, 29899,  7323,   322, 22467,  8541,   294,\n",
      "         29889,   450,  4272,   338,   884,  3271,   304,  5112]],\n",
      "       device='cuda:0')\n",
      "tensor([[12027,  7420,   304,   592,  1048,   278,  7483,  4272,   310, 19109,\n",
      "         29889,    13,    13,  1068, 13296,   918, 29871, 29896, 29901,  1068,\n",
      "            13,    13,  1576,  7483,  4272,   310, 19109,   338,   922,  5059,\n",
      "         29889,   922,  5059,   338,   278, 10150, 25311,   275,   297,  4275,\n",
      "         19109,   322, 19700,   408,   278,  8604, 29892, 16375, 29892,   322,\n",
      "         17407,  4818,   310,   278,  4234, 29889,   739,   338,  5982,   297,\n",
      "           278,  6641,  5933,   760,   310,   278,  4234, 29892,  2978,   278,\n",
      "          1261,   309,  3673,  1891, 10640,   313, 23560, 29999, 29897,   393,\n",
      "          2903,  1078,   372,   515,  4644, 19109, 29889,    13,    13,  2008,\n",
      "          5059,   338,  2998,   363,   967,  5400,  2071,   952, 29883,  2390,\n",
      "           414, 29892,  1880, 29899, 11345,  1014,  1994, 29892,   322,  1835,\n",
      "          9257, 29892,  3704,   476, 29899,  7323,   322, 22467,  8541,   294,\n",
      "         29889,   450,  4272,   338,   884,  3271,   304,  5112]],\n",
      "       device='cuda:0')\n",
      "tensor([[12027,  7420,   304,   592,  1048,   278,  7483,  4272,   310, 19109,\n",
      "         29889,    13,    13,  1068, 13296,   918, 29871, 29896, 29901,  1068,\n",
      "            13,    13,  1576,  7483,  4272,   310, 19109,   338,   922,  5059,\n",
      "         29889,   922,  5059,   338,   278, 10150, 25311,   275,   297,  4275,\n",
      "         19109,   322, 19700,   408,   278,  8604, 29892, 16375, 29892,   322,\n",
      "         17407,  4818,   310,   278,  4234, 29889,   739,   338,  5982,   297,\n",
      "           278,  6641,  5933,   760,   310,   278,  4234, 29892,  2978,   278,\n",
      "          1261,   309,  3673,  1891, 10640,   313, 23560, 29999, 29897,   393,\n",
      "          2903,  1078,   372,   515,  4644, 19109, 29889,    13,    13,  2008,\n",
      "          5059,   338,  2998,   363,   967,  5400,  2071,   952, 29883,  2390,\n",
      "           414, 29892,  1880, 29899, 11345,  1014,  1994, 29892,   322,  1835,\n",
      "          9257, 29892,  3704,   476, 29899,  7323,   322, 22467,  8541,   294,\n",
      "         29889,   450,  4272,   338,   884,  3271,   304,  5112]],\n",
      "       device='cuda:0')\n",
      "35.8 s ± 402 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1\n",
    "out = model.generate(\n",
    "    input_ids = input_ids,\n",
    "    max_length = 128,\n",
    "    use_cache = False\n",
    ")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cmlc1ISCwi7n",
    "outputId": "cd9f33e2-ad95-4d01-9755-242c4cf0152f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12027,  7420,   304,   592,  1048,   278,  7483,  4272,   310, 19109,\n",
      "         29889,    13,    13,  1068, 13296,   918, 29871, 29896, 29901,  1068,\n",
      "            13,    13,  1576,  7483,  4272,   310, 19109,   338,   922,  5059,\n",
      "         29889,   922,  5059,   338,   278, 10150, 25311,   275,   297,  4275,\n",
      "         19109,   322, 19700,   408,   278,  8604, 29892, 16375, 29892,   322,\n",
      "         17407,  4818,   310,   278,  4234, 29889,   739,   338,  5982,   297,\n",
      "           278,  6641,  5933,   760,   310,   278,  4234, 29892,  2978,   278,\n",
      "          1261,   309,  3673,  1891, 10640,   313, 23560, 29999, 29897,   393,\n",
      "          2903,  1078,   372,   515,  4644, 19109, 29889,    13,    13,    13,\n",
      "          2008,  5059,   338,  2998,   363,   967,  5400,  2071,   952, 29883,\n",
      "          2390,   414, 29892,  1880, 29899, 11345,  1014,  1994, 29892,   322,\n",
      "          1835,  9257, 29892,  3704,   476, 29899,  7323,   322, 22467, 24615,\n",
      "         29889,   450,  4272,   338,   884,  3271,   304,  5112]],\n",
      "       device='cuda:0')\n",
      "tensor([[12027,  7420,   304,   592,  1048,   278,  7483,  4272,   310, 19109,\n",
      "         29889,    13,    13,  1068, 13296,   918, 29871, 29896, 29901,  1068,\n",
      "            13,    13,  1576,  7483,  4272,   310, 19109,   338,   922,  5059,\n",
      "         29889,   922,  5059,   338,   278, 10150, 25311,   275,   297,  4275,\n",
      "         19109,   322, 19700,   408,   278,  8604, 29892, 16375, 29892,   322,\n",
      "         17407,  4818,   310,   278,  4234, 29889,   739,   338,  5982,   297,\n",
      "           278,  6641,  5933,   760,   310,   278,  4234, 29892,  2978,   278,\n",
      "          1261,   309,  3673,  1891, 10640,   313, 23560, 29999, 29897,   393,\n",
      "          2903,  1078,   372,   515,  4644, 19109, 29889,    13,    13,    13,\n",
      "          2008,  5059,   338,  2998,   363,   967,  5400,  2071,   952, 29883,\n",
      "          2390,   414, 29892,  1880, 29899, 11345,  1014,  1994, 29892,   322,\n",
      "          1835,  9257, 29892,  3704,   476, 29899,  7323,   322, 22467, 24615,\n",
      "         29889,   450,  4272,   338,   884,  3271,   304,  5112]],\n",
      "       device='cuda:0')\n",
      "tensor([[12027,  7420,   304,   592,  1048,   278,  7483,  4272,   310, 19109,\n",
      "         29889,    13,    13,  1068, 13296,   918, 29871, 29896, 29901,  1068,\n",
      "            13,    13,  1576,  7483,  4272,   310, 19109,   338,   922,  5059,\n",
      "         29889,   922,  5059,   338,   278, 10150, 25311,   275,   297,  4275,\n",
      "         19109,   322, 19700,   408,   278,  8604, 29892, 16375, 29892,   322,\n",
      "         17407,  4818,   310,   278,  4234, 29889,   739,   338,  5982,   297,\n",
      "           278,  6641,  5933,   760,   310,   278,  4234, 29892,  2978,   278,\n",
      "          1261,   309,  3673,  1891, 10640,   313, 23560, 29999, 29897,   393,\n",
      "          2903,  1078,   372,   515,  4644, 19109, 29889,    13,    13,    13,\n",
      "          2008,  5059,   338,  2998,   363,   967,  5400,  2071,   952, 29883,\n",
      "          2390,   414, 29892,  1880, 29899, 11345,  1014,  1994, 29892,   322,\n",
      "          1835,  9257, 29892,  3704,   476, 29899,  7323,   322, 22467, 24615,\n",
      "         29889,   450,  4272,   338,   884,  3271,   304,  5112]],\n",
      "       device='cuda:0')\n",
      "tensor([[12027,  7420,   304,   592,  1048,   278,  7483,  4272,   310, 19109,\n",
      "         29889,    13,    13,  1068, 13296,   918, 29871, 29896, 29901,  1068,\n",
      "            13,    13,  1576,  7483,  4272,   310, 19109,   338,   922,  5059,\n",
      "         29889,   922,  5059,   338,   278, 10150, 25311,   275,   297,  4275,\n",
      "         19109,   322, 19700,   408,   278,  8604, 29892, 16375, 29892,   322,\n",
      "         17407,  4818,   310,   278,  4234, 29889,   739,   338,  5982,   297,\n",
      "           278,  6641,  5933,   760,   310,   278,  4234, 29892,  2978,   278,\n",
      "          1261,   309,  3673,  1891, 10640,   313, 23560, 29999, 29897,   393,\n",
      "          2903,  1078,   372,   515,  4644, 19109, 29889,    13,    13,    13,\n",
      "          2008,  5059,   338,  2998,   363,   967,  5400,  2071,   952, 29883,\n",
      "          2390,   414, 29892,  1880, 29899, 11345,  1014,  1994, 29892,   322,\n",
      "          1835,  9257, 29892,  3704,   476, 29899,  7323,   322, 22467, 24615,\n",
      "         29889,   450,  4272,   338,   884,  3271,   304,  5112]],\n",
      "       device='cuda:0')\n",
      "tensor([[12027,  7420,   304,   592,  1048,   278,  7483,  4272,   310, 19109,\n",
      "         29889,    13,    13,  1068, 13296,   918, 29871, 29896, 29901,  1068,\n",
      "            13,    13,  1576,  7483,  4272,   310, 19109,   338,   922,  5059,\n",
      "         29889,   922,  5059,   338,   278, 10150, 25311,   275,   297,  4275,\n",
      "         19109,   322, 19700,   408,   278,  8604, 29892, 16375, 29892,   322,\n",
      "         17407,  4818,   310,   278,  4234, 29889,   739,   338,  5982,   297,\n",
      "           278,  6641,  5933,   760,   310,   278,  4234, 29892,  2978,   278,\n",
      "          1261,   309,  3673,  1891, 10640,   313, 23560, 29999, 29897,   393,\n",
      "          2903,  1078,   372,   515,  4644, 19109, 29889,    13,    13,    13,\n",
      "          2008,  5059,   338,  2998,   363,   967,  5400,  2071,   952, 29883,\n",
      "          2390,   414, 29892,  1880, 29899, 11345,  1014,  1994, 29892,   322,\n",
      "          1835,  9257, 29892,  3704,   476, 29899,  7323,   322, 22467, 24615,\n",
      "         29889,   450,  4272,   338,   884,  3271,   304,  5112]],\n",
      "       device='cuda:0')\n",
      "tensor([[12027,  7420,   304,   592,  1048,   278,  7483,  4272,   310, 19109,\n",
      "         29889,    13,    13,  1068, 13296,   918, 29871, 29896, 29901,  1068,\n",
      "            13,    13,  1576,  7483,  4272,   310, 19109,   338,   922,  5059,\n",
      "         29889,   922,  5059,   338,   278, 10150, 25311,   275,   297,  4275,\n",
      "         19109,   322, 19700,   408,   278,  8604, 29892, 16375, 29892,   322,\n",
      "         17407,  4818,   310,   278,  4234, 29889,   739,   338,  5982,   297,\n",
      "           278,  6641,  5933,   760,   310,   278,  4234, 29892,  2978,   278,\n",
      "          1261,   309,  3673,  1891, 10640,   313, 23560, 29999, 29897,   393,\n",
      "          2903,  1078,   372,   515,  4644, 19109, 29889,    13,    13,    13,\n",
      "          2008,  5059,   338,  2998,   363,   967,  5400,  2071,   952, 29883,\n",
      "          2390,   414, 29892,  1880, 29899, 11345,  1014,  1994, 29892,   322,\n",
      "          1835,  9257, 29892,  3704,   476, 29899,  7323,   322, 22467, 24615,\n",
      "         29889,   450,  4272,   338,   884,  3271,   304,  5112]],\n",
      "       device='cuda:0')\n",
      "tensor([[12027,  7420,   304,   592,  1048,   278,  7483,  4272,   310, 19109,\n",
      "         29889,    13,    13,  1068, 13296,   918, 29871, 29896, 29901,  1068,\n",
      "            13,    13,  1576,  7483,  4272,   310, 19109,   338,   922,  5059,\n",
      "         29889,   922,  5059,   338,   278, 10150, 25311,   275,   297,  4275,\n",
      "         19109,   322, 19700,   408,   278,  8604, 29892, 16375, 29892,   322,\n",
      "         17407,  4818,   310,   278,  4234, 29889,   739,   338,  5982,   297,\n",
      "           278,  6641,  5933,   760,   310,   278,  4234, 29892,  2978,   278,\n",
      "          1261,   309,  3673,  1891, 10640,   313, 23560, 29999, 29897,   393,\n",
      "          2903,  1078,   372,   515,  4644, 19109, 29889,    13,    13,    13,\n",
      "          2008,  5059,   338,  2998,   363,   967,  5400,  2071,   952, 29883,\n",
      "          2390,   414, 29892,  1880, 29899, 11345,  1014,  1994, 29892,   322,\n",
      "          1835,  9257, 29892,  3704,   476, 29899,  7323,   322, 22467, 24615,\n",
      "         29889,   450,  4272,   338,   884,  3271,   304,  5112]],\n",
      "       device='cuda:0')\n",
      "5.55 s ± 620 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1\n",
    "out = model.generate(\n",
    "    input_ids = input_ids,\n",
    "    max_length = 128,\n",
    "    use_cache = True\n",
    ")\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN2e5ME0WzE9lb42W0GWiJi",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
