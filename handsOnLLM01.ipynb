{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/LeeSeungYun1020/HandsOnLargeLanguageModels/blob/main/handsOnLLM01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73eWPYEZIlvD"
   },
   "source": [
    "\n",
    "# 첫번째 텍스트 생성하기\n",
    "\n",
    "핸즈온 LLM 1장\n",
    "\n",
    "- Nvidia cuda 사용을 위해 런타임 교체 필요\n",
    "- 생각보다 시간 많이 필요..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlNN5a_xVoon"
   },
   "source": [
    "1. 언어 AI?\n",
    "  - 인공지능: 인간 지능에 가까운 작업을 수행하는 컴퓨터 시스템\n",
    "  - 언어 AI: 인간 언어를 이해, 처리, 생성하는 기술에 초점을 맞춘 AI\n",
    "\n",
    "2. 언어 AI의 역사\n",
    "  - Bag of Words\n",
    "    - 토큰화한 단어를 벡터로 표현, text 본질의 의미는 무시됨, 띄어쓰기 없는 언어 적용 불가\n",
    "  - word2vec\n",
    "    - RNN 인코더 -> 문맥 임베딩 -> RNN 디코더\n",
    "    - 임베딩으로 신경망을 학습(구성)하여 유사(경향)성을 측정, 정적이라 문맥 파악 어려움\n",
    "  - RNN + attention\n",
    "    - RNN 인코더 -> 어텐션 디코더\n",
    "    - RNN(순환신경망): 인코딩, 디코딩을 순차, 자기회귀적으로 수행하여 긴 문장을 처리\n",
    "    - 어텐션: 관련 있는 단어에 가중치를 부여하여 중요도를 판단\n",
    "  - Transforme(attention only)\n",
    "    - 트랜스포머 인코더(셀프 어텐션, 피드포워드 신경망) -> 트랜스포더 디코더(마스크드 셀프 어텐션, 인코더 어텐션, 피드포워드 신경망)\n",
    "    - RNN을 사용하지 않고 어텐션만 사용, 병렬 훈련으로 훈련 속도 향상\n",
    "    - 셀프 어텐션: 한 시퀀스 안에서 중요도를 판단하여 전체 시퀀스를 한 번에 처리\n",
    "    - 피드포워드 신경망: 입력이 출력으로 한 방향으로 전달되는 구조의 신경망\n",
    "    - 마스크드 셀프 어텐션: 미래 위치를 숨겨 앞서 생성된 위치를 중심으로 다음 생성할 단어 고려\n",
    "  - BERT\n",
    "    - 언어 표현 목적의 인코더 기반 모델, 전이 학습에 사용\n",
    "    - 마스크드 언어 모델링 기법 적용: 입력의 특정 부분을 숨긴 뒤 표현(예측)하도록 학습\n",
    "    - 모델 사전 훈련 후 특정 작업을 위한 미세 튜닝 진행(Ex: 분류, 유사 문장 판별, 개체 인식)\n",
    "  - GPT\n",
    "    - 언어 생성 목적의 디코더 기반 모델, 챗봇 훈련에 사용\n",
    "    - 파라미터를 통해 모델의 언어 이해\n",
    "    - 문맥 길이가 모델이 처리할 수 있는 최대 토큰 수를 나타내며, 자기회귀 성질에 따라 새로운 토큰이 생성되면서 현재 문맥 길이가 늘어남\n",
    "    - 표현 모델과 마찬가지로 미세 튜닝 가능(Ex: 채팅)\n",
    "\n",
    "3. LLM 정의\n",
    "  - 대규모 언어 모델(LLM)은 일반적으로 디코더 기반 생성 모델을 지칭\n",
    "  - 아주 임의적인 명칭으로 소규모 언어 모델이 더 강력한 성능을 내거나 생성 기능이 없는 모델이 있는 등 광범위한 범위로 확장\n",
    "\n",
    "4. 훈련 패러다임\n",
    "  - 언어 모델링\n",
    "    - 사전 훈련 단계로 LLM을 훈련시켜 모델이 문법, 맥락, 패턴 학습하여 베이스 모델 생성\n",
    "    - 많은 계산, 긴 훈련 시간 필요\n",
    "    - 다음 단어 예측 외 특정 작업에 맞춰지지 않아, 일반적으로 명령에 따르지 못함\n",
    "  - 미세 튜닝\n",
    "    - 사후 훈련 단계로 구체적인 작업을 수행하도록 훈련\n",
    "    - 언어 모델링 단계에 비해 초저비용\n",
    "\n",
    "5. 앱(용례)\n",
    "  - 리뷰 긍정도 분석\n",
    "  - 인기 이슈 파악\n",
    "  - 관련 문서 검색\n",
    "  - 외부 자원(문서, 도구)을 활용하는 LLM 챗봇\n",
    "  - 냉장고 사진으로 레시피 생성\n",
    "\n",
    "6. 책임\n",
    " - 편향과 공정, 책임과 투명성, 유해 콘텐츠 생성, 지적 재산권, 규제\n",
    "\n",
    "7. 인터페이스\n",
    "  - 비공개(독점) 모델\n",
    "    - 가중치, 구조 비공개\n",
    "    - GPT-4(오픈AI), Claude(엔트로픽)\n",
    "    - 유료 지원 및 서비스, 컴퓨팅 자원 불필요\n",
    "    - 미세 튜닝 불가, 공급자에 데이터 공유 필요\n",
    "  - 공개 모델\n",
    "    - 가중치, 구조 공개\n",
    "    - Phi(마이크로소프트), Llama(메타), Mistral(코히어)\n",
    "    - 사용자가 모델 완전히 제어 가능\n",
    "    - 구체적인 지식과 컴퓨팅 리소스 필요\n",
    "  - 프레임워크\n",
    "    - 과다하게 많은 프레임워크 출시 - 사용법이 유사하여 하나를 쓰면 다른걸 쓰는건 쉬움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bpOzvAcfIaTp"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568,
     "referenced_widgets": [
      "db85a47b4955406da9858f0e883981dd",
      "741a0db69cde4f7e9dbec7ae120242c2",
      "fa6602c1282748ea8c4187cbf9daabd1",
      "fa49e904609b4bd2856eebc35e503086",
      "b85671ffa47442629e84b629848ce413",
      "923315323c8b46f9bd4f865e9b5bbdc6",
      "7ad61671b37045eb9fcd82c3f5abfe1f",
      "87c3bed9f0cd49a696b120281cc9c181",
      "ae2807ced925447f87fc4d987b6f9403",
      "16e080719a6e4b1ab060faea6461f267",
      "1ab7797bc44d404f9441736e3a1ce96c",
      "0794b462ddde426fb21831289d8309f0",
      "a62dbace1145400a95dc80cd77414e61",
      "87b9da90b07a42bc8783187a8cdbd853",
      "68e5b519bc154bb88e933cd2a045bbd3",
      "bd5564c7e56741fdbddb34b88763617b",
      "4684f135fc49407ba5e4b964fb85b2b0",
      "72ac385becc04cc0b9eae95c3ea5ae5c",
      "ac635ee5ffb24a798335bd4fcee3a4b1",
      "bff656c5b6c7489c8e5b1e587a030e26",
      "a4a9205ce8fa4f27aa1f5d1ffa7e1dc7",
      "c93f7797c6e34323b97de00649fe8eb9",
      "679b46bea9e34200bd97dc71c04094ca",
      "f2c28fdf15cd42ec926c2882024f389d",
      "5a2d00ad087a4b988013c6da5ef259b3",
      "d744e5d9f1244277a89e7a9d486c4345",
      "c98410f17dac4e17960d623657a60a94",
      "f2517e5f51e04d42b0054e7f3a7e6238",
      "75cebd7c14fd4f8492ca9e89249740e9",
      "7f9f559baf1d472e91ff4fc73b061c8c",
      "aed88e09e8664b02adbebe620254b17c",
      "637cf906f8c64ed7bbb5d77cd2be0fde",
      "cf14ff192d484cb9a0900b8b43d9fbcf",
      "d2660bb3181c4b8ebfa9f0357f5cb274",
      "82e9be203bda44f596a9fecbb16f7faf",
      "8a26ab408ebb4418940c49a33edf1db6",
      "08e1e24883724649828f0224a11968b8",
      "a7dd45a3b149401682f52ebb6a9d2bd1",
      "b6bfb2d93ab549d299f87cac4effca04",
      "99790901cb6c4e6b87644fe49ec6fc2f",
      "158dbd3c061b4780a8e9f108ec35c087",
      "3e60e46046ec4662bcc8a839f123ee39",
      "23ad030a47694a6eb5aaf6e4f7c526d0",
      "be0463e88ea34133b65d264de0c77ea6",
      "3db1a11a2dc94021994248ec69176176",
      "340ac708cd4846d399fdebd3f3fc648d",
      "1b5b83da581c4554a449b2a27a5d54e0",
      "450d89049545482095726396a6f09998",
      "69dc195002f54624a01094ca7880efec",
      "9fb7f0604857437b96683d976aa7b2bc",
      "159011bb252d4c308e7b5ad85537edfb",
      "1fdb3f7bf3574e48818f4583ef21edd4",
      "a28a3b08b84c4331810e799d57ac857b",
      "e68d9e60132b416b83ee161775dfa0f0",
      "0f89175c6d7b4fd9848179779f043477",
      "d5ee850917d9445b912c0b04a1f70e43",
      "f7c4f8df1cdb42689c69fc1829a1b5c2",
      "a5ed5553d0e54eb2ac021036e1748046",
      "f9e278e3a6fc474987716a46afa25af8",
      "0862f37a63a04f8ca23d886832362725",
      "6c34d2134ce0480397dbeca8a9febba9",
      "664439a90f8f47f486887bc956703dc2",
      "34da1ee9600249f6ace86deeb2c18d04",
      "de27852c3bae4caa9c031ced09b2b0f3",
      "f2afe02efb904291aaa531b0b32886b2",
      "7882c73ac1134522a39daa891155c259",
      "f6dc3cdf6de14b6682ccf11b8fc7e44a",
      "190e18b05df44318a3adfef6d0842ded",
      "092ada5af47b43b48dec0f1c18fa552d",
      "3020954b71214230974c6d7dd0ff2f25",
      "829df73e6e244ff892d3e7161a8d852c",
      "28c5f4e4870b46d6a22249ac23721f45",
      "a1bdf31362014b788a397057e176c260",
      "ec2a132a61914a2ea8a6517236f2eaa7",
      "0e3e9c73b6a74541ae1aeb20f3b564ef",
      "2fbde41d81274b56bd1fc1aa5ed3eea1",
      "e21044491a274433ae24b0002539d14d",
      "b6fbffe504714ed6bf70e6d5492f3074",
      "ff12bae962e64aafa0212dcc49c5fee7",
      "e5b5f60b5b884c60927d50b90abdab27",
      "2d833bc0922c43978a4dc1dcba886559",
      "94ff60b5e1e64e19b513132129072b09",
      "037c455af5eb4e1e8943cbb8b57bd1ed",
      "3f9106084a9a4a8c863e4f45d4b34cfb",
      "a35d4c2817da486e8136732580e252a6",
      "cdd3ab7facf94526a906e082ee600426",
      "867198ff8b7e48e783ed1833d8df8d8f",
      "70086a6d0735410db773fc33cc18f664",
      "034a28a5e61540d993a2b9b1a0e949ed",
      "bfdf399b96a743b89d4da501ac00f219",
      "147a4d1344ad49d6a26ccf47361052de",
      "6325d943ebd64175a361bd3958dc8ccd",
      "44f9a56355cf4d1488f7b9d724d51af3",
      "7224d86c4a6f4bad85f5011802267f66",
      "c6854707fa474a46aa398a8c204153b7",
      "c078d679d02b43deb621c835ede20471",
      "304b6fcd9c7447c9a4948dec8d477bed",
      "5cba63e26e7e454da297881f998fab00",
      "ca2a4d53e9b549b495b4eb0aa85cf031"
     ]
    },
    "id": "c1fzIo0HQCcV",
    "outputId": "069ecc05-aa9b-4148-fa96-242843918b19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db85a47b4955406da9858f0e883981dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0794b462ddde426fb21831289d8309f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679b46bea9e34200bd97dc71c04094ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2660bb3181c4b8ebfa9f0357f5cb274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db1a11a2dc94021994248ec69176176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ee850917d9445b912c0b04a1f70e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6dc3cdf6de14b6682ccf11b8fc7e44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fbffe504714ed6bf70e6d5492f3074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034a28a5e61540d993a2b9b1a0e949ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "ce45747583b74c4c9297b478f6410459",
      "7d46aa2086e94391a6ad70c539ffc629",
      "b50bfefede3e41c786315c24499075ac",
      "63e8c6ec9e764956931ec658bfa24e69",
      "0c82ab5819b84b30aa872a76773eeb8b",
      "04af5e9e6ae041ed9be19ca432ae1fa8",
      "e9abb8bcc6a748bf8e99a0d37676afeb",
      "c42a68240bf94859af1f719f1a70fcb6",
      "c79a168f73924d308eea467c4f86c645",
      "979d41260b0547ea85d8af29031b1de8",
      "c6467c4da9864217bb155e19afe1010d",
      "bef2dfca73314b8ba9534fa45db3ff97",
      "a3842a6f263d4d8984735a03725f6f14",
      "c45efee768d742afb15c860bdd125aa8",
      "c56ae2e031ef49ecae7c6b15c920c566",
      "9f25cb77fc294b1a86e3b6f2c1e351ff",
      "211c032c6a354da79d58d14c0b933d47",
      "c0d7f6cef4344cc0a032b2803f587a09",
      "25600c1e837e4bb1acf9128df3a82deb",
      "e336d1bab541484bb7fc9ec0b4e3c6cd",
      "4bae4821d90c4735822a4faa803474c9",
      "ebffe2f208f74469be1e63b981f597c7",
      "81502305eaff42ea9a66f2bbecf89542",
      "c6a0c112bf8b4ed59b068b7e7a306697",
      "51f3d7f28f944cee909ee4c464a2561d",
      "84c7835fcc1b43ccbe1ba7278e32304d",
      "08af5a0197e4412c850eef51068dbce9",
      "e8e19c0386444cf8a172e4d8fe9ed0ea",
      "55387098ed3641589306ed51d0c6d4cc",
      "b1241fe6d2db4ec291293f8f245e17bf",
      "6660d31d9a7d4e7a83f4e7a5ecd2c921",
      "9fd951030fd541ff9cc2335dd3a7b7b8",
      "437c0edafb954db190da5d96255ee615",
      "760123214cb14879aa04443a6ea14c0f",
      "b5ae84213ca940a998f68fa38cb18f4b",
      "a1df757527564432a4d71206fa581ecb",
      "3cd85e53cbdd43ea92509db3499e7027",
      "19e013f545e64edb9e4126863d16d58b",
      "d313a76e26a64c4cbd848934862c2a98",
      "81a55206a17e40d99644b69b983d06ef",
      "ec4cf5b8b6874e9fa490c56c6dbae95c",
      "2520458dadf94a60a040cb0b4c980906",
      "28892730b4bc4755b569a72cc905db9b",
      "37815099861a4317a3c4b51f708ac0b9",
      "9ec58723f90144c4bada7d5d9d650971",
      "a41ad846a0d94a3ba599f2d843c48d2f",
      "482c486cc1104f708853219eec16981d",
      "bf7b86295025463ab9ae649194e04e0c",
      "a3611735ee324e658d4513cdf27bfb53",
      "baa43e798d7d40f8929945bbbf90fda8",
      "d03a4fc9ee51440aa190448a09303863",
      "9a26abece2d845f88e265acf2db55db7",
      "cd214df3c88a43b195010b443c4148eb",
      "e59508424b0640ee8188e5e7f833d33c",
      "d8d71f5aec464514a9afab401bf8d579"
     ]
    },
    "id": "27yEjU2aQEAN",
    "outputId": "8eadebad-1310-4871-af19-cee7d7e9c24d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce45747583b74c4c9297b478f6410459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef2dfca73314b8ba9534fa45db3ff97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81502305eaff42ea9a66f2bbecf89542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760123214cb14879aa04443a6ea14c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec58723f90144c4bada7d5d9d650971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aIKhjOryTk0O"
   },
   "outputs": [],
   "source": [
    "from transformers import pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujbTv0FBTpyH",
    "outputId": "653560a6-2ad8-4c5f-ccdc-cabc80066e0a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    return_full_text = False,\n",
    "    max_new_tokens = 500,\n",
    "    do_sample = False,\n",
    "    use_cache=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hMMBgrFVT_wZ",
    "outputId": "dbcd0b07-4f28-417b-f67d-5aff4c72975b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "Chickens are known for their clucking and pecking, but did you know they also have a talent for comedy? Here's a joke about chickens that will make you laugh:\n",
      "\n",
      "Why did the chicken join the circus?\n",
      "\n",
      "Because it wanted to be a \"cluck-per\"!\n",
      "\n",
      "This joke plays on the word \"performance\" and the fact that chickens are often associated with clucking. It's a light-hearted way to poke fun at the idea of chickens being entertainers.\n",
      "\n",
      "Remember, humor is subjective, so feel free to come up with your own chicken-themed jokes!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Create a funny joke about chickens\"\n",
    "output = generator(prompt)\n",
    "print(output[0][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPgvwTqa6ktpCUMv/FZeD/o",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
